#!/bin/bash
#SBATCH -N 1
#SBATCH -p GPU-shared
#SBATCH --ntasks-per-node 2
#SBATCH --gres=gpu:p100:1
#SBATCH -t 24:00:00

# This will request 2 CPU cores, an one P100 on a shared GPU node

set -x  # echo commands to stdout
set -u  # throw an error if unset variable referenced
set -e  # exit on error

# Purge all loaded modules when running a job file.
module purge
# Load CUDA 9 and SINGULARITY.
module load cuda/9.0
module load singularity

# Move into $PROJECT directory OR $SCRATCH directory to run things.
# Remember, save files into $PROJECT, where storage is not deleted after 30 days.
# Do NOT run jobs from Home.
cd /pylon5/cc5fp3p/kkhode/singularity/sandbox/maddpg/

# If you want to install new packages for your OWN environment,
# PLEASE REFER TO THE OTHER JOB FILE!

# Running the script PYTHON_SCRIPT inside the singularity: This is of the form:
# singularity exec <PATH_TO_IMAGE>/tf-gpu.img <PATH_TO_SCRIPT>/<SCRIPT_NAME>.py <ARGUMENTS>
singularity exec /pylon5/cc5fp3p/kkhode/singularity/tf-gpu.img ./experiments/runCustomScenario.bash

# I have used the flag #!/usr/bin/env python at the starting of my python scripts,
# otherwise you would run python scripts/PYTHON_SCRIPT.py above.
